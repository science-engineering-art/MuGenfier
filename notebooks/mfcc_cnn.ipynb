{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PauOcS3sfRZk"
      },
      "outputs": [],
      "source": [
        "!sudo add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!sudo apt-get update -qq 2>&1 > /dev/null\n",
        "!sudo apt -y install -qq google-drive-ocamlfuse 2>&1 > /dev/null\n",
        "!google-drive-ocamlfuse"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -qq w3m # to act as web browser\n",
        "!xdg-settings set default-web-browser w3m.desktop # to set default browser\n",
        "%cd /content\n",
        "!mkdir drive\n",
        "%cd drive\n",
        "!mkdir MyDrive\n",
        "%cd ..\n",
        "%cd ..\n",
        "!google-drive-ocamlfuse /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "zBrPeDD7l9Kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "W8iTuG8GfRZo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "data: dict\n",
        "epochs_ = 300\n",
        "lr = 0.001\n",
        "kernel = (2,2)\n",
        "size_images = (192, 256)\n",
        "channels = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "NOA88stDfRZp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def index_genre(genre, genres):\n",
        "    for (g,index) in zip(genres, range(len(genres))):\n",
        "        if(g == genre):\n",
        "            return index\n",
        "    return -1\n",
        "\n",
        "def get_data(data_path, genres, decoder, training_percentaje=0.6, validation_percentaje=0.2, test_percentaje=0.2):\n",
        "    \"\"\"\n",
        "    data_path: se le pasa la direccion de la carpeta donde se encuentra la base de datos.\n",
        "    genres: se le pasa una lista con los nombres da cada carpeta que contiene un genero dado.\n",
        "    decoder: funcion para decodificar el dato que se le pasa, por ejemplo en caso de imagenes habria hacer imread\n",
        "    \"\"\"\n",
        "\n",
        "    data_training = {'in': [], 'out': []}\n",
        "    data_validation = {'in': [], 'out': []}\n",
        "    data_test = {'in': [], 'out': []}\n",
        "    data_test_from_genre = { }\n",
        "\n",
        "    for genre in genres:\n",
        "        files = os.listdir(data_path + genre)\n",
        "        count = len(files)\n",
        "\n",
        "        data_test_from_genre[genre] = {'in': [], 'out': []}\n",
        "\n",
        "        for (filename, index) in zip(files, range(len(files))):\n",
        "            filepath = data_path + genre + '/' + filename\n",
        "\n",
        "            if (index < training_percentaje * count):\n",
        "                data_training['in'].append(decoder(filepath))\n",
        "                data_training['out'].append(index_genre(genre, genres))\n",
        "                continue\n",
        "\n",
        "            if (index < (training_percentaje + validation_percentaje) * count):\n",
        "                data_validation['in'].append(decoder(filepath))\n",
        "                data_validation['out'].append(index_genre(genre, genres))\n",
        "            else:\n",
        "                feature  = decoder(filepath)\n",
        "                index = index_genre(genre, genres)\n",
        "\n",
        "                data_test['in'].append(feature)\n",
        "                data_test['out'].append(index)\n",
        "\n",
        "                data_test_from_genre[genre]['in'].append(feature)\n",
        "                data_test_from_genre[genre]['out'].append(index)\n",
        "\n",
        "    data_training = {'in': np.array(data_training['in']),'out': np.array(data_training['out'])}\n",
        "    data_validation = {'in': np.array(data_validation['in']),'out': np.array(data_validation['out'])}\n",
        "    data_test = {'in': np.array(data_test['in']),'out': np.array(data_test['out'])}\n",
        "\n",
        "    # data_test_from_genre = { data_test_from_genre[g]:{'in': np.array(data_test_from_genre[g]['in']),'out': np.array(data_test_from_genre[g]['out'])} for g in data_test_from_genre }\n",
        "\n",
        "    for g in data_test_from_genre:\n",
        "        data_test_from_genre[g] =  {'in': np.array(data_test_from_genre[g]['in']),'out': np.array(data_test_from_genre[g]['out'])}\n",
        "    print(\"---------Loaded data-----------\")\n",
        "    return {\n",
        "        'data_training': data_training,\n",
        "        'data_validation': data_validation,\n",
        "        'data_testing': data_test,\n",
        "        'data_testing_from_genre': data_test_from_genre\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "R77H5JCvfRZs"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "def read_image(filepath):\n",
        "    global size_images\n",
        "    image = cv2.imread(filepath)\n",
        "    return cv2.resize(image, size_images)\n",
        "\n",
        "def read_gray_image(filepath):\n",
        "    global size_images\n",
        "    img_gray = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
        "    img_gray = np.expand_dims(img_gray, axis=-1)\n",
        "    return cv2.resize(img_gray, size_images)\n",
        "\n",
        "genres = ['blues', 'classical', 'country', 'disco',\n",
        "          'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
        "\n",
        "\n",
        "def get_data_mfcc(training_percentaje=0.6, validation_percentaje=0.2, test_percentaje=0.2):\n",
        "    data_path = '/content/drive/MyDrive/MFCC_dataset/'\n",
        "    # data_path = '/content/drive/MyDrive/GTZAN/Ensemble_Data/MFCC/test/'\n",
        "    return get_data(data_path, genres, read_image,training_percentaje,validation_percentaje,test_percentaje)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "uCHuoORLfRZx"
      },
      "outputs": [],
      "source": [
        "def mfcc_cnn_model(input_shape=(128, 96, 1), classes=10, filter_shape=(3, 3)):\n",
        "    X_input = keras.layers.Input(input_shape)\n",
        "\n",
        "    X = keras.layers.Conv2D(32, filter_shape, activation='relu')(X_input)\n",
        "\n",
        "    X = keras.layers.Conv2D(64, filter_shape, activation='relu')(X)\n",
        "    X = keras.layers.AveragePooling2D((2, 2))(X)\n",
        "\n",
        "    X = keras.layers.Conv2D(128, filter_shape, activation='relu')(X)\n",
        "    X = keras.layers.AveragePooling2D((2, 2))(X)\n",
        "\n",
        "    X = keras.layers.Conv2D(256, filter_shape, activation='relu')(X)\n",
        "    X = keras.layers.GlobalAveragePooling2D()(X)\n",
        "\n",
        "    X = keras.layers.Dense(256, activation='relu')(X)\n",
        "    X = keras.layers.Dense(128, activation='relu')(X)\n",
        "    X = keras.layers.Dense(64, activation='relu')(X)\n",
        "    X = keras.layers.Dense(32, activation='relu')(X)\n",
        "    X = keras.layers.Dense(classes, activation='softmax')(X)\n",
        "\n",
        "    return keras.models.Model(inputs=X_input, outputs=X, name='SpectrogramCNN')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = get_data_mfcc(training_percentaje=0.8, validation_percentaje=0.1, test_percentaje=0.1)\n",
        "print(f\"Train Count: {len(data['data_training']['in'])}. \\nValidation Count: {len(data['data_validation']['in'])}. \\nTest Count: {len(data['data_testing']['in'])}\")"
      ],
      "metadata": {
        "id": "oRRsaHDJ6yDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "ogMq2ce7fRZv"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "def training():\n",
        "    global data\n",
        "    global epochs_\n",
        "    global size_images\n",
        "    global lr\n",
        "    global channels\n",
        "    global history\n",
        "\n",
        "    training_data = data['data_training']\n",
        "    v_data = data['data_validation']\n",
        "\n",
        "    model = mfcc_cnn_model(input_shape=(\n",
        "        size_images[1], size_images[0], channels), classes=10, filter_shape=kernel)\n",
        "\n",
        "    model.compile(\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
        "        metrics=['accuracy'])\n",
        "\n",
        "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "        '/content/drive/MyDrive/mfcc_models/best_weights.h5',\n",
        "        save_weights_only=True,\n",
        "        save_best_only=True,\n",
        "        monitor='val_accuracy',\n",
        "        mode='max')\n",
        "\n",
        "    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.2,\n",
        "        patience=20,\n",
        "        min_lr=0.001)\n",
        "\n",
        "    history = model.fit(\n",
        "        training_data['in'], training_data['out'],\n",
        "        validation_data=(v_data['in'], v_data['out']),\n",
        "        epochs=epochs_,\n",
        "        callbacks=[checkpoint]\n",
        "        )\n",
        "\n",
        "    with open('/content/drive/MyDrive/mfcc_models/history.pkl', 'wb') as file:\n",
        "        pickle.dump(history.history, file)\n",
        "\n",
        "    model.save('/content/drive/MyDrive/mfcc_models/mfcc_model.h5')\n",
        "    return history\n",
        "\n",
        "def testing(model_name=\"mfcc_model.h5\"):\n",
        "    global data\n",
        "\n",
        "    input = data['data_testing']['in']\n",
        "    output = data['data_testing']['out']\n",
        "\n",
        "    path = '/content/drive/MyDrive/mfcc_models/' + model_name\n",
        "    model = keras.models.load_model(path)\n",
        "\n",
        "    score = model.evaluate(input, output, verbose=0)\n",
        "    # print('testing loss: ' + str(score[0]))\n",
        "    print('testing accuracy: ' + str(score[1]))\n",
        "\n",
        "    input = data['data_validation']['in']\n",
        "    output = data['data_validation']['out']\n",
        "    score = model.evaluate(input, output, verbose=0)\n",
        "    # print('validation loss: ' + str(score[0]))\n",
        "    print('validation accuracy: ' + str(score[1]))\n",
        "\n",
        "    input = data['data_training']['in']\n",
        "    output = data['data_training']['out']\n",
        "    score = model.evaluate(input, output, verbose=0)\n",
        "    # print('training loss: ' + str(score[0]))\n",
        "    print('training accuracy: ' + str(score[1]))\n",
        "\n",
        "def testing_for_genre(model_name=\"mfcc_model.h5\"):\n",
        "    path = '/content/drive/MyDrive/mfcc_models/' + model_name\n",
        "    model = keras.models.load_model(path)\n",
        "\n",
        "    genres_data = data['data_testing_from_genre']\n",
        "    for genre in genres_data:\n",
        "        input = genres_data[genre]['in']\n",
        "        output = genres_data[genre]['out']\n",
        "\n",
        "        score = model.evaluate(input, output, verbose=0)\n",
        "        print(f'{genre} accuracy: ' + str(score[1]))\n",
        "        # print(f'{genre} loss: ' + str(score[0]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def plot_training(history):\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Precisión del modelo')\n",
        "    plt.ylabel('Precisión')\n",
        "    plt.xlabel('Época')\n",
        "    plt.legend(['Entrenamiento', 'Validación'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Pérdida del modelo')\n",
        "    plt.ylabel('Pérdida')\n",
        "    plt.xlabel('Época')\n",
        "    plt.legend(['Entrenamiento', 'Validación'], loc='upper left')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "AwPFyft53jjC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save Weights in Model\n",
        "def save_weights(model_name=\"mfcc_model.h5\", epoch_name = 'best_weights.h5'):\n",
        "    path = '/content/drive/MyDrive/mfcc_models/' + model_name\n",
        "    path_best_epoch = '/content/drive/MyDrive/mfcc_models/' + epoch_name\n",
        "    model = keras.models.load_model(path)\n",
        "    model.load_weights(path_best_epoch)\n",
        "    model.save('/content/drive/MyDrive/mfcc_models/mfcc_model.h5')\n"
      ],
      "metadata": {
        "id": "Iz-4TrvzXAVs"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1_3ChDmfRZy"
      },
      "outputs": [],
      "source": [
        "history = training()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iyZvYv3fRZy"
      },
      "outputs": [],
      "source": [
        "save_weights()\n",
        "testing()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing_for_genre()"
      ],
      "metadata": {
        "id": "Q8-C-qw-QxUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_training(history)"
      ],
      "metadata": {
        "id": "kMGf-OjX_1tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "88DNwf0LIpfH"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/mfcc_models/mfcc_model.h5'\n",
        "model = keras.models.load_model(path)\n",
        "predictions = model.predict(data['data_testing']['in'])\n",
        "rounded_predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_true=data['data_testing']['out'], y_pred=rounded_predictions)"
      ],
      "metadata": {
        "id": "8maAhmODIaeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "GENRES = ['blues', 'classical', 'country', 'disco',\n",
        "          'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
        "\n",
        "def plot_confusion_matrix(y_test, y_pred, save_as:str, title:str='Confusion Matrix'):\n",
        "    # create confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    if not isinstance(save_as, str):\n",
        "        save_as = f'conf_matrix_{time.time()}.png'\n",
        "\n",
        "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    # plot confusion matrix\n",
        "    plt.figure(figsize=(8,6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    tick_marks = np.arange(len(GENRES))\n",
        "    plt.xticks(tick_marks, GENRES, rotation=45)\n",
        "    plt.yticks(tick_marks, GENRES)\n",
        "\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                horizontalalignment=\"center\",\n",
        "                color=\"white\" if cm[i, j] > (cm.max() / 2) else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.savefig(save_as)"
      ],
      "metadata": {
        "id": "FC3Rv7I_Sddo"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(rounded_predictions ,data['data_testing']['out'],\"MFCC confusion matrix\")"
      ],
      "metadata": {
        "id": "lgg6jjNaL2j0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}