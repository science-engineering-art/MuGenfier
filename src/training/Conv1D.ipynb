{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "NZeYhJTxNFbG",
        "vUlanSmm8gV3"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# importacion 'os'"
      ],
      "metadata": {
        "id": "kr7m2p-TM7kx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bD-EWVxxlKj2"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Montando Drive"
      ],
      "metadata": {
        "id": "NZeYhJTxNFbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lcVdR1bT_Z2E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c34d98c-8555-40cc-b1f5-bd9c6694fa2a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importando y descargando GTZAN üëáüèª"
      ],
      "metadata": {
        "id": "Lmfc5ZyiLkNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "api_token = {\"username\":\"franciscoayracacceres\",\"key\":\"0faed9196b5d77ac39f381ebcbcea42e\"}"
      ],
      "metadata": {
        "id": "nqe4CE2HBtKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "QTFZv1yBLzGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "PGHAWChHL0ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "RZjVWJxCCdQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "STn6wTHuCyBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets list"
      ],
      "metadata": {
        "id": "lmpYk3LaDG0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle config set -n path -v drive/MyDrive/ML_DATABASE/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQDK9MhPEuyQ",
        "outputId": "90ab0058-f173-412e-b4c8-e933a38d3ad2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- path is now set to: drive/MyDrive/ML_DATABASE/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download --unzip andradaolteanu/gtzan-dataset-music-genre-classification --force"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2hKiVRkDsZo",
        "outputId": "c94b303a-c407-4e52-f7d0-31874f1f0070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading gtzan-dataset-music-genre-classification.zip to drive/MyDrive/ML_DATABASE/datasets/andradaolteanu/gtzan-dataset-music-genre-classification\n",
            "100% 1.21G/1.21G [00:30<00:00, 45.5MB/s]\n",
            "100% 1.21G/1.21G [00:30<00:00, 42.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"drive/MyDrive/ML_DATABASE\")"
      ],
      "metadata": {
        "id": "Bh3aCVvjKt7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "kcF47LmF9Aww"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conv1D"
      ],
      "metadata": {
        "id": "1l381I3vMZ_s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importaciones"
      ],
      "metadata": {
        "id": "CP9ieecVO3Et"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, MaxPooling1D, Dense, Dropout, Flatten\n",
        "from keras.layers import BatchNormalization, Activation\n",
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "6gsJspMiO753"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Asegurando el uso de gpu para la creacion, sosten y uso de la red convolucional"
      ],
      "metadata": {
        "id": "uk_hYDGaeQxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "assert device_name == '/device:GPU:0', \"mira la nota a la derecha para activar el uso de GPU\"\n",
        "\n",
        "print('se encontro una gpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGoC22BPeioH",
        "outputId": "ad5ea8c7-d7e2-4fb9-f27b-393795f24a3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "se encontro una gpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/My Drive/ML_DATABASE/datasets/andradaolteanu/gtzan-dataset-music-genre-classification/Data/genres_original\"\n",
        "assert os.listdir(path)"
      ],
      "metadata": {
        "id": "wVna4lC8_LVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "## <center>Trabajo con histogramas</center>\n",
        "\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "tSYMUXsYhh5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv"
      ],
      "metadata": {
        "id": "ZPRfVzWU6r8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "histograms_path = \"/content/drive/My Drive/ML_DATABASE/datasets/andradaolteanu/gtzan-dataset-music-genre-classification/Data/images_original\"\n",
        "\n",
        "import cv2\n",
        "songs = []\n",
        "genres = []\n",
        "\n",
        "image_1d_shape = 373248\n",
        "\n",
        "for genero in os.listdir(histograms_path):\n",
        "  for histogram in os.listdir(os.path.join(histograms_path, genero)):\n",
        "    song = cv2.imread(os.path.join(os.path.join(histograms_path, genero), histogram))\n",
        "    songs.append(np.reshape(song, (image_1d_shape,)))\n",
        "    genres.append(genero)\n",
        "  print(f\"{genero} leido\")\n",
        "\n",
        "X, y = np.array(songs), np.array(genres)"
      ],
      "metadata": {
        "id": "81YOZpx1hiU_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c5ae9ea-8b0f-40b8-ee84-559d740b19b0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "blues leido\n",
            "classical leido\n",
            "country leido\n",
            "disco leido\n",
            "hiphop leido\n",
            "jazz leido\n",
            "metal leido\n",
            "pop leido\n",
            "reggae leido\n",
            "rock leido\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "\n",
        "  # ENCODE LABELS\n",
        "  encoder = LabelEncoder()\n",
        "  y = encoder.fit_transform(y)\n",
        "  y = to_categorical(y, num_classes=10)  # Assuming 10 genres\n",
        "\n",
        "  # PARTICIONAR LOS DATOS\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "  X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "  # REMODELAR LOS DATOS\n",
        "  X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "  X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)\n",
        "  X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "  # MODELO DE CNN 1D BASADO EN LA ARQUITECTURA ResNet\n",
        "  model = Sequential()\n",
        "\n",
        "  # PRIMERA CAPA DE CONVOLUCION\n",
        "  model.add(Conv1D(32, kernel_size=3, strides=1, padding=\"same\", input_shape=(X_train.shape[1], 1)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(\"relu\"))\n",
        "\n",
        "  # BLOQUES RESIDUALES\n",
        "  for _ in range(1):\n",
        "      model.add(Conv1D(64, kernel_size=3, strides=1, padding=\"same\"))\n",
        "      model.add(BatchNormalization())\n",
        "      model.add(Activation(\"relu\"))\n",
        "      model.add(Conv1D(364, kernel_size=3, strides=1, padding=\"same\"))\n",
        "      model.add(BatchNormalization())\n",
        "      model.add(Activation(\"relu\"))\n",
        "\n",
        "  # CAPA DE POOLING\n",
        "  model.add(MaxPooling1D(pool_size=2, strides=2))\n",
        "\n",
        "  # CAPA CONECTADA COMPLETAMENTE\n",
        "  model.add(Flatten())\n",
        "  # model.add(Dense(16, activation=\"relu\"))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(10, activation=\"softmax\"))  # Assuming 10 genres\n",
        "\n",
        "  # COMPILACION DEL MODELO\n",
        "  model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])\n",
        "\n",
        "  # ENTRENAMIENTO\n",
        "  model.fit(X_train, y_train, batch_size=80, epochs=100, validation_data=(X_val, y_val))\n"
      ],
      "metadata": {
        "id": "OHWQKoMFxmir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del model, encoder, X_train, X_test, y_train, y_test, X_val, y_val\n",
        "# !nvidia-smi"
      ],
      "metadata": {
        "id": "hJUAxMNJPivg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "vo1PtMlghizI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "## <center>Trabajo con audios(Dataset virgen)</center>\n",
        "\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "UX4sHS4ChzCq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lectura del dataset"
      ],
      "metadata": {
        "id": "TouAnLqWTEee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CARGAR UN ARCHIVO DE AUDIO\n",
        "def load_audio_file(file_path):\n",
        "    input_length = 660000  # This is 15 seconds with 44100 sample rate\n",
        "    data = librosa.core.load(file_path, sr=22050)[0]  # We use librosa to load audio file with sample rate 22050\n",
        "    if len(data) > input_length:\n",
        "        data = data[:input_length]\n",
        "    else:\n",
        "        data = np.pad(data, (0, max(0, input_length - len(data))), \"constant\")\n",
        "    return data\n"
      ],
      "metadata": {
        "id": "4Ba314P44V-F"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CARGAR EL CONJUNTO DE DATOS\n",
        "def load_dataset(path):\n",
        "    genres = os.listdir(path)\n",
        "    X, y = [], []\n",
        "    for genre in genres:\n",
        "        genre_path = os.path.join(path, genre)\n",
        "        for file_name in os.listdir(genre_path):\n",
        "            file_path = os.path.join(genre_path, file_name)\n",
        "            try:\n",
        "              data = load_audio_file(file_path)\n",
        "              # print(f\"audio {file_name} cargado\")\n",
        "            except:\n",
        "              print(f\"error con {file_name}\")\n",
        "              continue\n",
        "            X.append(data)\n",
        "            y.append(genre)\n",
        "        print(f\"genero {genre} completado\")\n",
        "    return np.array(X), np.array(y)\n",
        "\n"
      ],
      "metadata": {
        "id": "8SMaTsPa4p4x"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = load_dataset(path)"
      ],
      "metadata": {
        "id": "_z9W8SD-dq8W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a42b66ce-ab79-407c-93bc-4a7350f7559c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "genero blues completado\n",
            "genero classical completado\n",
            "genero country completado\n",
            "genero disco completado\n",
            "genero hiphop completado\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-a661506bab05>:4: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  data = librosa.core.load(file_path, sr=22050)[0]  # We use librosa to load audio file with sample rate 22050\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error con .ipynb_checkpoints\n",
            "genero jazz completado\n",
            "genero metal completado\n",
            "genero pop completado\n",
            "genero reggae completado\n",
            "genero rock completado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creacion del modelo "
      ],
      "metadata": {
        "id": "OR5UrunIdnbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "\n",
        "  # ENCODE LABELS\n",
        "  encoder = LabelEncoder()\n",
        "  y = encoder.fit_transform(y)\n",
        "  y = to_categorical(y, num_classes=10)  # Assuming 10 genres\n",
        "\n",
        "  # PARTICIONAR LOS DATOS\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "  X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "  # REMODELAR LOS DATOS\n",
        "  X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "  X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)\n",
        "  X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "  # MODELO DE CNN 1D BASADO EN LA ARQUITECTURA ResNet\n",
        "  model = Sequential()\n",
        "\n",
        "  # PRIMERA CAPA DE CONVOLUCION\n",
        "  model.add(Conv1D(32, kernel_size=3, strides=1, padding=\"same\", input_shape=(X_train.shape[1], 1)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(\"relu\"))\n",
        "\n",
        "  # BLOQUES RESIDUALES\n",
        "  for _ in range(1):\n",
        "      model.add(Conv1D(32, kernel_size=3, strides=1, padding=\"same\"))\n",
        "      model.add(BatchNormalization())\n",
        "      model.add(Activation(\"relu\"))\n",
        "      model.add(Conv1D(32, kernel_size=3, strides=1, padding=\"same\"))\n",
        "      model.add(BatchNormalization())\n",
        "      model.add(Activation(\"relu\"))\n",
        "\n",
        "  # CAPA DE POOLING\n",
        "  model.add(MaxPooling1D(pool_size=2, strides=2))\n",
        "\n",
        "  # CAPA CONECTADA COMPLETAMENTE\n",
        "  model.add(Flatten())\n",
        "  # model.add(Dense(512, activation=\"relu\"))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(10, activation=\"softmax\"))  # Assuming 10 genres\n",
        "\n",
        "  # COMPILACION DEL MODELO\n",
        "  model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])\n",
        "\n",
        "  # ENTRENAMIENTO\n",
        "  model.fit(X_train, y_train, batch_size=80, epochs=100, validation_data=(X_val, y_val))\n"
      ],
      "metadata": {
        "id": "tZrY7nJJ43Ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "kp8fp_XHhzC0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Liberacion de recursos"
      ],
      "metadata": {
        "id": "1TxCpG-Cd9BW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numba"
      ],
      "metadata": {
        "id": "xBa5zvb3UL4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numba import cuda\n",
        "device = cuda.get_current_device() \n",
        "device = cuda.select_device(0)\n",
        "\n",
        "device.reset()\n"
      ],
      "metadata": {
        "id": "w0aC97l7UOlg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!service networking restart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJEzQsLDd8uI",
        "outputId": "66bf5c2a-a1a0-4875-fc6e-2324254890e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "networking: unrecognized service\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kill -9 -1"
      ],
      "metadata": {
        "id": "HNCjP38leIfb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}